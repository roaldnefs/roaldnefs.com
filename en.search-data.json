{"/about/":{"data":{"":"Roald is Chief Technology Officer at Warpnet with over ten years of Security and Platform Engineering experience at various companies like DUO, KPN and CJIB.\nHe has made several contributions to open source, to tools such as SaltStack, Prometheus, rfcat and many more. Besides contributing to open source Roald enjoys tinkering with electronics, hardware hacking, and software development in general.\nPlease find him on LinkedIn for a more detailed description of his full work experience, education and certification."},"title":"About Roald Nefs"},"/posts/":{"data":{"":"RSS Feed"},"title":"Blog"},"/posts/2019/01/software-defined-radio-on-linux/":{"data":{"":"In the quick start guide for Software Defined Radio (SDR) on Linux we will listen to some very common frequencies using a RTL-SDR. SDR is a radio communication system where traditional hardware components are instead implemented in software. Some common low-cost DVB-T USB dongles with the Realtek RTL2832U controller and tuner can be used as a wide-band SDR receiver.","air-traffic-monitoring#Air traffic monitoring":"You can monitor air traffic using an RTL SDR and the dump1090 package. Start by downloading and compiling the dump1090 package:\ngit clone https://github.com/MalcolmRobb/dump1090.git cd dump1090 make To run dump1090 in interactive mode, with networking support, you will need to run the following command:\n./dump1090 --interactive --net Open your browser and open http://localhost:8080/ to see live air traffic:","gqrx-sdr#Gqrx SDR":"Gqrx is an open source software defined radio receiver. The package has been included in Ubuntu for many years, but you probably want to install a newer version using the official personal package archive (PPA).\nsudo add-apt-repository -y ppa:bladerf/bladerf sudo add-apt-repository -y ppa:myriadrf/drivers sudo add-apt-repository -y ppa:myriadrf/gnuradio sudo add-apt-repository -y ppa:gqrx/gqrx-sdr sudo apt-get update sudo apt-get install gqrx-sdr It is recommended that you also install the libvolk1-bin package and run volk_profile tool to optimize GNU Radio performance on your own computer.\nsudo apt-get install libvolk1-bin volk_profile On the first startup of Gqrx you will need to configure your device using the following settings:\nDevice: Realtek RTL2838xxx Device string: rtl=0 Input rate: 1800000 Decimation: None Bandwidth: 0 MHz LNB LO: 0 MHz Note: you can always change your device configuration by clicking the circuit board icon in the menu.\nLookup the frequency of one of your local radio stations and update the frequency in the Receiver Options tab on the right side of Gqrx. Don’t forget to set the mode to WFM (mono) or WFM (stereo). You might need to change the gain in order to hear something.","p2000#P2000":"P2000 is a one-way communications network for pagers based on the FLEX-protocol developed by Motorola. The P2000 network is used by the emergency services in the Netherlands. The FLEX-protocol does not provide encryption, so you can read the messages yourself using an RTL-SDR.\nIn order to receive and decode the FLEX messages we will be using multimon-ng, which can be installed from source:\ngit clone https://github.com/EliasOenal/multimon-ng.git cd multimon-ng mkdir build cd build cmake .. make sudo make install Connect your RTL-SDR and run the following command to receive the FLEX messages send on the P2000 network.\nrtl_fm -f 169.65M -M fm -s 22050 | multimon-ng -a FLEX -t raw /dev/stdin Note: it might take several minutes before you start receiving any message, you can always check an online P2000 feed for messages appearing in your local region.","prerequisites#Prerequisites":"Start by installing the required packages for downloading and compiling the rtl-sdr package. The libusb-1.0-0-dev package provides a C library used for accessing USB devices (e.g. the RTL-SDR).\nsudo apt-get install git cmake build-essential libusb-1.0-0-dev After retrieving the required packages you will be able to clone, build and compile the RTL-SDR Osmocom drivers from source.\ngit clone git://git.osmocom.org/rtl-sdr.git cd rtl-sdr/ mkdir build cd build cmake ../ -DINSTALL_UDEV_RULES=ON make sudo make install sudo ldconfig sudo cp ../rtl-sdr.rules /etc/udev/rules.d/ The RTL-SDR is normally used as a TV device and doesn’t work for SDR purposes if we don’t block the default drivers. Create a file called /etc/modprobe.d/blacklist-rtl.conf using root privileges with the following content:\nblacklist dvb_usb_rtl28xxu Save the file and reboot your system. You can test the RTL-SDR by running the following command rtl_test -t. The output will look similar to this:\nFound 1 device(s): 0: Realtek, RTL2838UHIDIR, SN: 00000001 Using device 0: Generic RTL2832U OEM Found Rafael Micro R820T tuner Supported gain values (29): 0.0 0.9 1.4 2.7 3.7 7.7 8.7 12.5 14.4 15.7 16.6 19.7 20.7 22.9 25.4 28.0 29.7 32.8 33.8 36.4 37.2 38.6 40.2 42.1 43.4 43.9 44.5 48.0 49.6 [R82XX] PLL not locked! Sampling at 2048000 S/s. No E4000 tuner found, aborting.","raspberry-pi-as-a-rf-transmitter#Raspberry Pi as a RF transmitter":"Using the rpitx package you can turn your Raspberry Pi in a simple radio frequency transmitter. It will be able to handle frequencies between 5KHz and 1500MHz. This includes some common frequencies (e.g. 433MHz).\nNote: it might not be legal to transmit on all available frequencies, check your local regulations before transmitting anything!\nYou will need to plug a wire on GPIO 4, which will act as the antenna. I’ve used a cheap breadboard cable (see the picture below). The optimal length of the wire depends on the frequency, but a few centimeters should be fine for local testing.\nAfter installing Raspbian you can install the rpitx package using the following commands.\ngit clone https://github.com/F5OEO/rpitx cd rpitx ./install.sh sudo reboot After rebooting the Raspberry Pi you can go to your rpitx folder and launch easytest.sh:\ncd rpitx ./easytest.sh Using your SDR receiver you will be able to monitor the transmitted signals. Try to send the some test signals on the 434 MHz, the rpitx default band."},"title":"Software Defined Radio on Linux"},"/posts/2019/01/update-yard-stick-one-firmware/":{"data":{"":"Today I received my YARD Stick One (Yet Another Radio Dongle) created by Great Scott Gadgets. The dongle can transmit and receive digital wireless signals at frequencies below 1GHz. The YARD Stick One is not a SDR, because the I/Q samples are directly demodulated by the chipset instead of send to the host over USB. The YARD Stick One therefore isn’t compatible with any SDR software, but you can use something called rfcat.\nRfcat allows the user to drive the YARD Stick One using Python and abstracts a lot if complexity. The YARD Stick One has rfcat pre-installed, with a USB bootloader to update the firmware. I’ve received the YARD Stick One with outdated firmware, so I wanted to update it before using it any further.\nThis post is specifically written for Ubuntu 18.04 and may not work as intended on other versions or newer releases. Be sure to verify compatibility if you’re using a different version of Ubuntu. Start by cloning the rfcat repository:\n$ git clone https://github.com/atlas0fd00m/rfcat.git $ cd rfcat In order to allow non-root access to the YARD Stick One you will need to update your udev rules using the following commands:\n$ sudo cp etc/udev/rules.d/20-rfcat.rules /etc/udev/rules.d $ sudo udevadm control --reload-rules From within the rfcat directory you can install the software by running the install script:\n$ sudo python setup.py install Once I started the interactive Python shell for rfcat I was greeted by the following error message:\n$ rfcat -r Traceback (most recent call last): File \"/usr/local/bin/rfcat\", line 8, in from rflib import * File \"/usr/local/lib/python2.7/dist-packages/rflib/__init__.py\", line 2, in from chipcon_nic import * File \"/usr/local/lib/python2.7/dist-packages/rflib/chipcon_nic.py\", line 4, in import usb ImportError: No module named usb Install the missing dependencies. Make sure you install the correct version of sdcc because the newer version of sdcc seems to break according to #39 and #42.\n$ sudo apt install python-usb libusb-1.0.0 sdcc I was now able to start the Python interactive shell for rfcat and printed the YARD Stick One radio configuration by running the print d.reprRadioConfig() command.\n$ rfcat -r Error in resetup():Exception('No Dongle Found. Please insert a RFCAT dongle.',) Error in resetup():Exception('No Dongle Found. Please insert a RFCAT dongle.',) Error in resetup():Exception('No Dongle Found. Please insert a RFCAT dongle.',) Error in resetup():Exception('No Dongle Found. Please insert a RFCAT dongle.',) Error in resetup():Exception('No Dongle Found. Please insert a RFCAT dongle.',) Error in resetup():Exception('No Dongle Found. Please insert a RFCAT dongle.',) Error in resetup():Exception('No Dongle Found. Please insert a RFCAT dongle.',) Error in resetup():Exception('No Dongle Found. Please insert a RFCAT dongle.',) Error in resetup():Exception('No Dongle Found. Please insert a RFCAT dongle.',) Error in resetup():Exception('No Dongle Found. Please insert a RFCAT dongle.',) Error in resetup():Exception('No Dongle Found. Please insert a RFCAT dongle.',) No module named IPython.frontend.terminal.interactiveshell 'RfCat, the greatest thing since Frequency Hopping!' Research Mode: enjoy the raw power of rflib currently your environment has an object called \"d\" for dongle. this is how you interact with the rfcat dongle: \u003e\u003e\u003e d.ping() \u003e\u003e\u003e d.setFreq(433000000) \u003e\u003e\u003e d.setMdmModulation(MOD_ASK_OOK) \u003e\u003e\u003e d.makePktFLEN(250) \u003e\u003e\u003e d.RFxmit(\"HALLO\") \u003e\u003e\u003e d.RFrecv() \u003e\u003e\u003e print d.reprRadioConfig() \u003e\u003e\u003e print d.reprRadioConfig() == Hardware == Dongle: YARDSTICKONE Firmware rev: 0348 Compiler: Not found! Update needed! Bootloader: CC-Bootloader == Software == rflib rev: 65535 ... Take note of the following message in de radio configuration:\nFirmware rev: 0348 Compiler: Not found! Update needed!\nThe firmware seems to be outdated and my YARD Stick One came without compiler installed. I wanted to update my dongle before using in any further. In order to set in in bootloader mode I used the d.bootloader() command and the LEDs on the YARD Stick One started flashing.\n$ rfcat -r \u003e\u003e\u003e d.bootloader() In another terminal window I changed the directory to rfcat/firware and made sure the rfcat_bootloader command was in my path. This command is used to install the new firmware on the dongle.\n$ cd rfcat/firmware $ which rfcat_bootloader /usr/local/bin/rfcat_bootloader I issued the make installRfCatYS1CCBootloader command to update the firmware.\n$ make installRfCatYS1CCBootloader After checking the radio configuration of my YARD Stick One, the firmware seems to be updated.\n$ rfcat -r \u003e\u003e\u003e print(d.reprRadioConfig()) == Hardware == Dongle: YARDSTICKONE Firmware rev: 5535 Compiler: SDCCv350 Bootloader: CC-Bootloader == Software == rflib rev: 65535 ... RfCat, the greatest thing since Frequency Hopping!","enable-bootloader-mode-when-the-firmware-isnt-running#Enable bootloader mode when the firmware isn’t running":"The bootloader mode on the YARD Stick One can be triggered by connecting pins 7 and 9 on the P1 expansion header.\n----------------------------------------- | YARD Stick One 2 4 6 8 10 12 14 | | 1 3 5 7 9 11 13 ------ | USB | | ------ | | ----------------------------------------- EDIT: I’m currently running Ubuntu 19.04 and thus installed sdcc version 3.9.0, which results in the same errors as #42. Version 3.5.0 of sdcc seems to work fine. I was able to ground pin 7 and pin 9 on the YS1 using a paperclip."},"title":"Update YARD Stick One Firmware"},"/posts/2019/12/hardware-reverse-a-wireless-router/":{"data":{"":"Last week I’ve bought a Rigol DS1102E digital oscilloscope and was very eager to test it out. When going to my bin of old hardware I’ve found a Sitecom Wireless Router 150N X1. After opening up the router I immediately spotted the UART debugging interface (top left in the picture). In this post we will go through the process of connecting to an unknown serial interface.\nThe UART debugging interface wasn’t labeled, so I had to figure out what each port was doing. The two pins on the right are directly connected to the IC, so I figured that those to are the RX and TX ports. By connecting a multi meter to the two left most pins I’ve found that the serial port is using 3.3V and the left most connector is the VCC followed by the GND pin. By connecting the ground lead of the multi meter to GND pin on the serial interface I quickly spotted RX port (positive voltage). From left to right the pins are: VCC, GND, TX and RX.\nWe now know the operating voltage and pin layout of the serial interface but the baud rate is still unknown, so I’ve connected my new oscilloscope to the GND and TX pins on the serial interface and set it to trigger on a pulse. After power cycling the router is saw the following signal:\nBy determining the length of the shortest pulse I was able to figure out the baud rate using the following formula: 1 / time * 106, in my case: 1 / (886µs / 870µs) * 106 = 62500. But this isn’t a usual baud rate, so I took once that was closest to 62500: 57600.\nThe USB to TTL module (PL2303) I had laying around operated on 5V, because I was not willing to risk breaking the router I had to down convert to voltage to 3.3V. This can be done using a bi-directional logic level converter.\nUsing the USB to serial connection we are able to connect to the router using minicom with the following command: minicom -b 57600 -8 -D /dev/ttyUSB0. After power cycling the router, the following output appears:\nAccording the the boot log the Sitecom Wireless Router 150N X1 is using Linux!"},"title":"Hardware Reversing the Sitecom Wireless Router 150N X1"},"/posts/2020/01/ding-dong-ditch-using-sdr-and-arduino/":{"data":{"":"In this post we will be building a device to play Ding Dong Ditch digitally. The device will ring the doorbell every several seconds without pressing the button. This project is all about reverse engineering radio frequencies using a RLT-SDR and creating hardware using an Arduino.\nThis project is heavily based upon the Digital Ding Dong Ditch by Samy Kamkar.\nThe video is a short demonstration of the Ding Dong Ditch device. Once it’s powered by USB (or a battery) it will send out a RF signal every few seconds which will ring the doorbell.","creating-the-arduino#Creating the Arduino":"For sending signal we demodulated earlier, I’m using a 433MHz ASK transmitter hooked up to my Arduino nano clone according to the following Fritzing sketch:\nThe script for the Arduino can be found on the following GitHub repository: github.com/roaldnefs/ding-dong-ditch. It uses the RCSwitch library for sending the signal. This library is written for power outlet sockets but my doorbell uses the same protocol.\nOnce the Arduino is powered over USB or by battery, the doorbell should start ringing!","hardware#Hardware":"RTL-SDR: The RTL-SDR is an inexpensive software defined radio using a Realtek chip. The dongle can be used to receive a wide range of frequencies, including those of some wireless doorbells.\nArduino: In this post I will be using an Arduino Nano clone. Arduino is a great platform for cheap and rapid creation of hardware.\n433MHz ASK RF Transmitter: For sending the RF signal I will be using a FS1000A (433MHz) RF transmitter. You might want to locate your frequency first, before buying a transmitter for a specific frequency.","locate-the-signal#Locate the Signal":"We will start by locating the signal send when pressing the doorbell button. On most devices you will find the frequency on the device itself. In my case the doorbell receiver clearly states that it uses the 433MHz frequency:\nUsing Gqrx with the RTL-SDR connected to your computer, you will be able to spot signal while pressing the doorbell button.\nIf you aren’t able to locate the frequency of your doorbell (or you simple cannot find the doorbell receiver), you can always keep pressing the doorbell while you scroll through the spectrum in Gqrx. You might want to check the 315MHz, 433MHz and 900MHz bands first, because they are among the most frequently used bands.\nI was able to locate my doorbell signal on 433.879MHz.","recording-and-demodulating-the-signal#Recording and Demodulating the Signal":"Modulation allow data to be transmitted via radio via radio frequencies. After locating the signal you’ll need to determine the type of modulation used by the doorbell. By looking at the waterfall in Gqrx I was able to determine that the signal send by the doorbell is amplitude modulated. The most common modulation schemes you will see in radio are:\nAmplitude Modulation (AM) Frequency Modulation (FM) Phase Modulation (PM) Amplitude modulation, as the name might suggest, modulates the amplitude while frequency modulation will modulate the frequency. If you are listing to 100.0 FM radio, the signal is actually send between 99.995MHz and 100.005MHz.\nBy the looks of it, the signal seems to be using amplitude modulation. Using rtl_fm and sox you can record the AM data into a wav file:\nrtl_fm -M am -f 433879000 -s 2000000 - | sox -t raw -r 2000000 -e signed-integer -b 16 -c 1 -V1 - doorbell.wav Since we are dealing with digital information (1s and 0s) the modulation will be more discrete than just AM, common schemes are:\nAmplitude Shift Keying (ASK) Frequency Shift Keying (FSK) Phase Shift Keying (PSK) When looking at the audio in Audacity it appears to be sending the same signal multiple times in a row.\nIf we zoom in to take a closer look at the signal, we can easily see the highs (1s) and lows (0s).\nThe high and low signals aren’t appearing to be the same length, but the two same patterns keep reappearing:\n﹍|﹉﹉|, the high signal seems to be twice as long as the low signal ﹍﹍|﹉|, the low signal seems to be twice as long as the high signal This is something called Pulse Width Modulation (PWM). If we interpret the first signal as a 1 and the second signal as a 0, then we will end up with something like this:\nYou might want to check multiple samples because the signal isn’t very clear on some spots. Examples of a 1 and 0 signal are shown below:\nYou will be able to get the same result much faster using rtl_433. It might be a good idea to verify you manually demodulated signal using rtl_433 before creating the Arduino. In my case it guesses the modulation type to be Pulse Width Modulation, after demodulation using rtl_433 I end up with the same 1s and 0s as I’ve found manually.","requirements#Requirements":"For this project you will need several tools and modules to record and send the signal.","software#Software":"RTL-SDR \u0026 GQRX: RTL-SDR and Gqrx will be used to locate, record and visualise the radio signal. Instruction about installing RTL-SDR and Gqrx on Linux can be found in Software Defined Radio on Linux post.\nAudacity: Audacity is used for taking a closer look at the radio signal in order to demodulate it by hand.\nDing Dong Ditch: The Arduino sketch for this project can be found at my GitHub: github.com/roaldnefs/ding-dong-ditch."},"title":"Ding Dong Ditch using SDR and Arduino"},"/posts/2020/04/getting-started-with-git/":{"data":{"":"","checking-the-status#Checking the Status":"The git status command is used to determine state state of all the files in your Git repository. Directly after cloning a new repository the output will look similar to this:\n$ git status On branch master Your branch is up to date with 'origin/master'. nothing to commit, working tree clean The clean working tree means that you have a clean working directory without any modified tracked files. The moment you add a new file in will be listed as untracked. If we for example create a new file called README it will be listed under the untracked section in the git status command:\n$ git status On branch master Your branch is up to date with 'origin/master'. Untracked files: (use \"git add ...\" to include in what will be committed) README nothing added to commit but untracked files present (use \"git add\" to track) Using the -s flag we can also show a shorter status report:\n$ git status -s ?? README","clone-an-existing-repository#Clone an Existing Repository":"In addition to creating new repositories you can also clone existing one using the git clone command. This allows you to get a local copy of the repositories on GitHub or GitLab for example. Where the git checkout command will just get a working copy, the git clone command receives a full copy of nearly all data that is known on the remote repository you’re cloning.\nTo clone this blog for example (also a Git repository), you can run the following command to receive a full copy:\n$ git clone https://github.com/roaldnefs/roaldnefs.com.git This will create a directory called roaldnefs.com in the current working directory. In order to specify a target directory use the following command:\n$ git clone $ git clone https://github.com/roaldnefs/roaldnefs.com.git blog Besides the https:// protocol you can also use the git:// or SSH protocol to clone a repository.","commiting-changes#Commiting Changes":"At this moment we are able to stage our changes for the next commit, to create the actual commit we can use the git commit command. When executed only the staged changes will be added to the commit. The simplest way te create a commit is using the git commit command itself. This will launch the editor of your choice (see First-Time Git Setup):\n$ git commit Your editor will display the following text:\n# Please enter the commit message for your changes. Lines starting # with '#' will be ignored, and an empty message aborts the commit. # # On branch master # Your branch is up to date with 'origin/master'. # # Changes to be committed: # new file: README # The text contains the commented out git status report. You will be able to type a descriptive commit message and save the commit. At the moment the commit message is saved, the commit is created. If you just want to add a single line commit message you can also use the -m option to supply your message:\n$ git commit -m 'Add the README file' [master 4c822a3] Add the README file 1 file changed, 1 insertion(+) create mode 100644 README After creating the commit the git commit command will show you the branch (master) you commited to, the SHA-1 checksum (4c822a3), the number of changed files, and statistics about the lines added and removed in the commit.\nThe image below shows four commits being created on the master branch:","first-time-git-setup#First-Time Git Setup":"After installing Git you might want to customize your Git environment using the git config command. There are three places where the configuration can be stored:\n/etc/gitconfig file, contains the configuration applied to every user on the system. To set system wide configuration, you can use the --system option while using the git config command. ~/.gitconfig or ~/.config/git/config file, contains the global configuration for your user. To set global configuration you can use the --global option. the config file in the repositories Git directory (.git/config), the configuration set in the file will only be used for repository it’s set on. To set configuration options on a repository level you can execute the git config command without specifying the --system or --global options. Every commit in Git contains information about the author, therefore we want to start by configuring our username and email address using the following commands:\n$ git config --global user.name \"John Doe\" $ git config --global user.email johndoe@example.com The --global option indicates that we want to store the configuration in the ~/.gitconfig or ~/.config/git/config file. If you want to overwrite these option on a specific repository, you can simply omit the --global option while executing the above commands from within the directory of your local repository.\nBy default Git will use your system’s default text editor. To choose a different text editor you can run the following command which will set vim as the editor when something needs to be typed in Git (e.g. Git commit message):\n$ git config --global core.editor vim Using the git config --list command you can list your current Git configuration. To show a specific setting, you can for example invoke the git config user.name command which will only show the configured username.","getting-a-git-repository#Getting a Git Repository":"There are two ways to obtain a Git repository, in both cases you will end up with a local Git repository:\nYou can clone an existing repository, or You can turn a local directory into a new repository.","getting-help#Getting Help":"Git comes packed with detailed manpages (manual pages) which can be read by invoking the following commands:\n$ git help $ git --help $ man git- To show the manpages for the git commit run the following command for example:\n$ git help config If you are only looking for an overview of the available options, simply append the the Git command the the -h flag, e.g.: git commit -h.\nBesides the manpages for all the Git commands you will find the following guide to be very useful:\ngit help tutorial - A tutorial introduction to Git. git help everyday - A useful minimum set of commands for everyday Git. git help revisions - Specifying revisions and ranges for Git. git help workflows - An overview of recommended workflows with Git.","getting-started#Getting Started":"Before we dive into Git, lets take a quick look at the terminology.","git-basics#Git Basics":"After Git has been set up, we are ready to start using Git the way it was intended. In this chapter we will cover most of the basic commands, by the end you should have enough knowledge about Git to start working on actual Git repositories.","ignoring-files#Ignoring Files":"You don’t always want Git to track all files in a directory. If you are working on a Python project you probably want Git to ignore the byte source files (*.pyc). That’s possible using the .gitignore file, any matched pattern in this file will be ignored be Git. Below you will find an example for Python projects:\n# Byte-compiled / optimized / DLL files __pycache__/ *.py[cod] *$py.class GitHub maintains a Git project including the .gitignore files for the most common languages and frameworks on: github.com/github/gitignore.","introduction#Introduction":"Git is a free and opensource distributed version control system designed to handle everything from small to very large projects with speed and efficiency. While working with Git I often get asked questions about best practices or the more advanced usage of Git e.g.: a rebase, merge conflict or how to cherry pick. This post will serve as my personal Git reference as well as a getting started guide for my colleagues and friends.\nKeep in mind that I am absolutely no wizard in the area of Git, so improvements, feedback and additions to this post are always welcome! In the near future this blog will be expanded considerably, but I will also try to make regular updates after that.","moving-files#Moving Files":"Git doesn’t always automatically track file movement. If your want to rename or move a file you can use the git mv command:\n$ git mv README README.txt $ git status On branch master Your branch is ahead of 'origin/master' by 1 commit. (use \"git push\" to publish your local commits) Changes to be committed: (use \"git restore --staged ...\" to unstage) renamed: README -\u003e README.txt This is equivalent to running something like this:\n$ mv README README.txt $ git rm README $ git add README.txt Make sure to read the next post in the Git series about Git Braching.","recording-changes-to-the-repository#Recording Changes to the Repository":"After creating or cloning a repository you have a local copy of the project. In most cases you want to start making changes to the project and commit them to the repository so that each change is recorded as a snapshot of the repository.\nWithin the repository files can reside in two states: tracked or untracked. After cloning an existing repository all files are tracked, the moment you edit the file they become untracked. If a file has changed, (re)moved or renamed it become modified compared to the last commit. Those changes can be staged in the Git index to be added to the next commit. The lifecycle of files within the Git repository looks like this:\nThe paragraphs below will further explain the files states.","removing-files#Removing Files":"To remove a tracked file in Git you will have to use the git rm command. This will remove the file in your staging area whereby you can commit the deletion. The git rm command will also delete the file from your working directory. If we for example delete the tracked README file the output of the git status command will look similar to this:\n$ git status On branch master Your branch is ahead of 'origin/master' by 1 commit. (use \"git push\" to publish your local commits) Changes to be committed: (use \"git restore --staged ...\" to unstage) deleted: README If you already staged a change for a file you actual like to remove, you will have to use the -f option to force the deletion:\n$ git rm -f README","staging-modified-files#Staging Modified Files":"Besides adding new files to the Git index we can also stage modified files using the git add command. After modifying the existing config.yaml file the git status report shows the following content:\n$ git status On branch master Your branch is up to date with 'origin/master'. Changes to be committed: (use \"git restore --staged ...\" to unstage) new file: README Changes not staged for commit: (use \"git add ...\" to update what will be committed) (use \"git restore ...\" to discard changes in working directory) modified: config.yaml To stage the modified config.yaml run the git add config.yaml command followed by a git status command:\n$ git add config.yaml $ git status On branch master Your branch is up to date with 'origin/master'. Changes to be committed: (use \"git restore --staged ...\" to unstage) new file: README modified: config.yaml If you modify the config.yaml after staging it, it will be listed in both the tracked and untracked section of the git status report:\n$ git status On branch master Your branch is up to date with 'origin/master'. Changes to be committed: (use \"git restore --staged ...\" to unstage) new file: README modified: config.yaml Changes not staged for commit: (use \"git add ...\" to update what will be committed) (use \"git restore ...\" to discard changes in working directory) modified: config.yaml If you would create a commit at this point, only the last set of changes (tracked) would be added to the commit. Use the git add config.yaml command again to also stage your newly created changes.","terminology#Terminology":"A few Git terms which are used within this post:\nrepository - A collection of commits, branches and tags related to a single project. working tree - The tree of actual checked out files. The working tree contains the contents of the HEAD’s commit tree and any local changes not yet commited. index - Also known as the staging area. The index is used to build a set of changes to be commited together. When looking at the working directory, only the changed that are marked to be commited are called the index. commit - Single point in the Git history, also seen as a snapshot of the working tree at some point in time. branch - An alternative line of development. tag - Points to another tag of commit. master - The default development branch, although this might be changed. Whenever a Git repository is created, the master branch is also created and becomes the active branch. HEAD - The current branch.","the-thee-states#The Thee States":"Within Git your files can reside in three states: modified, staged and commited. In the modified state, files have been changed but aren’t committed to the Git database yet. In the staging state, changed files are marked in there current version to be added to the next commit snapshot. In the last commited state, the commits are stored in the local Git database.\nAn example of a typical Git workflow using the specified stages:\nWhen a project in checked out in the working directory, the files at a specific moment in time are pulled out of the Git database and placed in the Git directory to be modified. When a user has made some changes to the files, they can be staged to the next commit in the staging area. Within the Git terminology the staging area is known as the index. When a commit is made, the changes that where staged, will be saved to the Git database.\nWhen a file is changed but not yet added to the index, it’s called modified. All changes that where added to the index are called staged. Only after saving the staged changes to the Git database they are considered commited.","tracking-new-files#Tracking New Files":"To start tracking any new files using Git, we can use the git add command which will track and add the changes to be staged for the next commit. To track the newly created README file, run the following command:\n$ git add README The git status command will now list the file as being staged:\n$ git status On branch master Your branch is up to date with 'origin/master'. Changes to be committed: (use \"git restore --staged ...\" to unstage) new file: README","turn-a-local-directory-into-a-repository#Turn a Local Directory into a Repository":"If you want to start controlling a directory with Git you can use the git init command the initialize the Git repository:\n$cd ~/my_project $ git init This creates the .git directory containing all the information about your newly created repository. At the start of a new repository nothing is tracked yet, if you want to start tracking existing files you can create an initial commit. First add the files to the Git index using the git add command, followed by a git commit:\n$ git add *.py $ git add README.md $ git commit -m 'Initial commit'","viewing-staged-and-unstaged-changes#Viewing Staged and Unstaged Changes":"The git status command only lists the changed files, if you als want to know what has been changed in the file contents then you can use the git diff command. The git diff command will show the exact lines that have been updated, added or removed. The example below will show the line “This is a new line in the README file!” being added as the first line in the README file:\n$ git diff diff --git a/README b/README index e69de29..d818324 100644 --- a/README +++ b/README @@ -0,0 +1 @@ +This is a new line in the README file! By default the git diff command will only show the unstaged changes in tracked files. When the changes are added to the Git index, they won’t be shown in the git diff output unless you run the git diff --staged command which will show the comparison between the staged changes and your last commit."},"title":"Getting Started with Git"},"/posts/2020/04/how-to-create-a-visual-studio-code-extension-pack/":{"data":{"":"Within Visual Studio Code you will often find yourself installing multiple extensions for a certain language or framework. You might want to share those collections of extensions with your friends or colleagues, be able to easily disable or enable the full collection of extensions or provide a curated list of extensions for a blog post. Then you will find the Visual Studio Code Extension Packs to be very useful. In this blogpost, we’ll create a Extension Pack for SaltStack requested in korekontrol/vscode-saltstack#5.","conclusion#Conclusion":"Creating an extension pack for Visual Studio Code is very simple, using the provided scaffolding tools you will only need to add the extensions to the pack. Checkout the warpnet.saltstack-extension-pack on the VS Code marketplace and GitHub.","generating-a-new-extension-pack#Generating a new Extension Pack":"With the required tools installed, we are able scaffold a new extension pack project. Invoke the VS Code Extension Generator using the following command:\n$ yo code Select the New Extension Pack option in the dropdown list:\nFill out the prompted fields for a new extension pack:\nAfter scaffolding the extenions pack you can open the project in VS Code and update the package.json to include the extensions you would like to add to your extension pack:\n{ \"name\": \"saltstack-extension-pack\", \"displayName\": \"saltstack-extension-pack\", \"description\": \"SaltStack Extension Pack\", \"version\": \"0.0.1\", \"engines\": { \"vscode\": \"^1.44.0\" }, \"categories\": [ \"Extension Packs\" ], \"extensionPack\": [ \"warpnet.salt-lint\", \"korekontrol.saltstack\" ] } In the above example we’ve added the following extensions to the pack in the format of .:\nwarpnet.salt-lint korekontrol.saltstack If your want to publish your extension to the VS Code marketplace you might want to add some additional information to the package.json such as the publisher name, homepage and repository URL. You will end up with a package.json similar to this:\n{ \"name\": \"saltstack-extension-pack\", \"displayName\": \"saltstack-extension-pack\", \"description\": \"SaltStack Extension Pack\", \"version\": \"0.0.1\", \"publisher\": \"warpnet\", \"homepage\": \"https://github.com/warpnet/saltstack-extension-pack\", \"repository\": { \"type\": \"git\", \"url\": \"https://github.com/warpnet/saltstack-extension-pack.git\" }, \"engines\": { \"vscode\": \"^1.44.0\" }, \"categories\": [ \"Extension Packs\" ], \"keywords\": [ \"saltstack\", \"salt\", \"salt-lint\" ], \"extensionPack\": [ \"warpnet.salt-lint\", \"korekontrol.saltstack\" ] }","installing-the-required-tools#Installing the required tools":"The most simple way to create an VS Code extension is using the Yeoman VS Code extension generator. Make sure you have Node.js and Git installed, then install Yeoman and the VS Code Extension Generator with the following command:\n$ npm install -g yo generator-code","package--publish-the-extension-pack#Package \u0026amp; Publish the Extension Pack":"We can use the vsce (Visual Studio Code Extensions) command-line tool to package, publish and manage VS Code extensions. Install vsce using the following command:\n$ npm install -g vsce Use the vsce package command to package the extension pack:\n$ vsce package DONE Packaged: /Users/roald/Documents/projects/saltstack-extension-pack/saltstack-extension-pack-0.0.1.vsix (6 files, 3.08KB) This will generate a *.vsix file that is needed to publish the extension pack to the VS Code marketplace. In addition to the *.vsix we’ll also need a personal access token for Azure DevOps to publish the extension pack.\nFirst, make sure you have an Azure DevOps organization. From your organization’s home page (e.g. https://dev.azure.com/warpnet/), open the user settings dropdown menu next to your profile image and select Personal access tokens. On the Personal access tokens page, click the New Token button and the give the token a name and select a custom defined scope ruleset and click Show all scopes. Scroll down the list of possible scopes until you find Marketplace and select both Acquire and Manage. Now click Create to show the newly created Personall Acces Token.\nUsing the newly generated token we can create a publisher using the vsce create-publisher command. The name of the publisher need to be the same as the one provided in the package.json file.\nIf you already create a publisher before you can simply invoke the vsce login command and supply your newly created token.\nNow simply invoke the vsce publish command and within a few minutes the extension pack is available on the VS Code marketplace:\n$ vsce publish Publishing warpnet.saltstack-extension-pack@0.0.1... DONE Published warpnet.saltstack-extension-pack@0.0.1 Your extension will live at https://marketplace.visualstudio.com/items?itemName=warpnet.saltstack-extension-pack (might take a few minutes for it to show up)."},"title":"How To Create a Visual Studio Code Extension Pack"},"/posts/2020/05/git-branching/":{"data":{"":"","basic-branching-and-merging#Basic Branching and Merging":"","basic-merge-conflict#Basic Merge Conflict":"When the same part of a file has been changed in two branches the merging process doesn’t go smoothly and results in a merge conflict. If for example both the hotfix and develop branch changed the same line in the README.md file, you would get a merge conflict that looks like this:\n$ git merge develop Auto-merging README.md CONFLICT (content): Merge conflict in README.md Automatic merge failed; fix conflicts and then commit the result. Git wasn’t able the merge the develop branch and left the README.md unmerged as show by the git status command:\n$ git status On branch master You have unmerged paths. (fix conflicts and run \"git commit\") (use \"git merge --abort\" to abort the merge) Unmerged paths: (use \"git add ...\" to mark resolution) both modified: README.md no changes added to commit (use \"git add\" and/or \"git commit -a\") Git will add standard conflict-resolution markers the the file(s) that have conflicts, so you can manually resolve them. In this example those conflict-resolution markers in the README.md file look like this:\n\u003c\u003c\u003c\u003c\u003c\u003c\u003c HEAD Added this line in the hotfix branch. ======= Added this line in the develop branch. \u003e\u003e\u003e\u003e\u003e\u003e\u003e develop This means the version in HEAD (the master branch, as hotfix branch has been fast-forward merged into master) is the top part of the block, while the version in develop is everything in the bottom part. To resolve the conflict you have to choose one side or edit the contents yourself. You might resolve the conflict by replacing the entire block with:\nAdded this line in the hotfix and develop branch. After resolving the conflict, run git add on each file to mark it as resolved. To conclude the merge run git commit afterward:\n$ git add README.md $ git commit [master f7f17db] Merge branch 'develop'","basic-merging#Basic Merging":"What if instead of creating a commit directory on the master branch we would have created branch called hotfix, made a single commit, and wanted to merge it back into master?\nYou can do that using the git merge command. This example below will merge the hotfix branch back into master.\n$ git checkout master Switched to branch 'master' $ git merge hotfix Updating 8fb061c..527a84d Fast-forward README.md | 2 +- 1 file changed, 1 insertion(+), 1 deletion(-) Because the commit C4 pointed to by the branch hotfix was directly ahead of the commit C3, the commit previously pointed to by themaster branch, Git was able to perform a “fast-forward” merge. During a fast-forward merge the pointer is moved forward. This only happens when you try to merge one commit that can be reached by following the firs commit’s history. After merging the master and hotfix branch point to the same commit.\nWhile the hotfix branch was merged into master the develop branch diverged from master, containing two extra commits. If we wanted to merge develop into master the situation would look similar to this:\nUsing the git merge command we can merge develop into master:\n$ git checkout master $ git merge develop Merge made by the 'recursive' strategy. LICENSE | 0 1 file changed, 0 insertions(+), 0 deletions(-) create mode 100644 LICENSE Instead of the “fast-forward” stategy it now used a “recursive” strategy. This is because the commit on the develop branch isn’t a clear ancestor of the master branch. Git simply does a three-way merge, using the two snapshots pointed to by the branch tips and the common ancestor of the two, this results in a merge commit (C7). Compared to a normal commit, a merge commits has more than one parent.\nAfter merging develop, the branch can be removed using the git branch command combined with the -b option:\n$ git branch -d develop","branching-workflows#Branching Workflows":"","cherry-pick#Cherry Pick":"The git cherry-pick isn’t directly related to Git branches, it however allows you to pick arbitrary commits by reference and append them to your current working HEAD. During cherry-picking you pick a commit from a branch and apply it to another. This is especially useful when you accidentally applied the a commit to the wrong branch, you can switch to the correct branch and cherry-pick the commit to where it should belong.\nGit cherry-pick will however cause duplicate commits, and in most cases a normal merge is perferred. Even though the changes in the cherry-picked commit are the same, the SHA-1 checksum changes. This might confuse other colleborators as the original and picked commit might look different.\nLet’s assume we want to apply the hotfix C4 already merged in the develop to the master branch without merging all the other changes currently in the develop branch. You can execute a git cherry-pick command to pick C4 into the master branch:\n$ git checkout master $ git cherry-pick C4 Where C4 should be the commit SHA1-checksum of the original C4 commit. This results in only the hotfix being picked into the master branch:\nIt’s also possible to cherry-pick multiple commits. We could’ve have picked the commits C4 up to C7 using the following command:\n$ git checkout master $ git cherry-pick C4..C7 Where both C4 and C7 should be the SHA1-checksum of the original commits. This will not pick C4, to include C4 using the following command:\n$ git checkout master $ git cherry-pick C4^..C7 The first commit (C4) should be older then the second commit (C7), otherwise Git will silently fail.","creating-a-new-branch#Creating a New Branch":"Using the git branch command you can create a new branch. The command below will create a new branch called develop. This creates a new pointer to the same commit, but didn’t switch to the newly created branch!\n$ git branch develop In the image below you also see a special pointer called HEAD, pointing to the master branch. Even though we’ve created a new branch called develop, HEAD is stil pointing to the master branch.\nUsing the git log with the --decorate option shows you where the branch pointers are pointing. In the example below HEAD is pointing to master, while both master and develop are pointing to the same commit.\n$ git log --oneline --decorate 3c71f2e (HEAD -\u003e master, develop) Update README.md 13d0d67 Initial commit","fetching#Fetching":"Just like normal branches, local and remote work can diverge. In the example below the local master branch in one commit forward of the remote-tracking origin/master branch:\nTo synchronize your work you can run the git fetch command, e.g. git fetch origin. In the above example this will lookup the alias alias (in this case https://github.com/roaldnefs/roaldnefs.com.git), and fetch any data from it, and update your local database, moving the origin/master pointer forward if a new commit has been added the to remote repository in the meanwhile.","introduction#Introduction":"Like other version control systems Git also support a way to diverge from the main line of development and continue to do work without messing with that main line, it’s called branching. Unlike may other version control systems, the Git branching model is lightweight. Each Git branch is simply just a file containing the 40 character SHA-1 checksum of the commit it points to. You can nearly instantaneous create or switch branches. It’s therefore not surprising that Git users are encouraged to use workflows that branch and merge often.\nIf you’re new to Git make sure to read Getting Started with Git to get familiar with the basics of Git before diving into Git Branching.\nA brach in Git is simply a movable pointer to one of the commits in a Git repository. The default branch name in Git is master, it is exactly like any other branch. The only difference is the master branch is automatically created by the git init command.","pulling#Pulling":"While the git fetch command fetches all the remote changes, it won’t change you working directory at all. There is however a command called git pull which will execute git fetch and immediately followed by a git merge in most cases.\nAs the git pull wil often be confusing it’s better to simply use the git fetch and git merge commands explicitly. If you are uncertain about any diverged history you can run the git pull --ff-only command. The --ff-only option will resolve the merge as a fast-forward when possible. When this is impossible, it will refuse to merge and exit with an error.","pushing#Pushing":"You local branches aren’t automatically shared with the world, you will need to push them explicitly up to a remote. If you have a branch named hotfix that you want to push to a remote repository you can run the git push origin hotfix command, e.g.:\n$ git push origin hotfix Counting objects: 19, done. Delta compression using up to 8 threads. Compressing objects: 100% (12/12), done. Writing objects: 100% (20/20), 1.21 KiB | 0 bytes/s, done. Total 20 (delta 2), reused 0 (delta 0) To https://github.com/roaldnefs/roaldnefs.com * [new branch] hotfix -\u003e hotfix The next time someone else fetches change from the server, they will get a reference to where the server’s version of hotfix is under the remote branch origin/hotfix:\n$ git fetch origin remote: Counting objects: 5, done. remote: Compressing objects: 100% (2/2), done. remote: Total 2 (delta 0), reused 2 (delta 0) Unpacking objects: 100% (3/3), done. From https://github.com/roaldnefs/roaldnefs.com * [new branch] hotfix -\u003e origin/hotfix To merge the changes in the origin/hotfix branch, you can run the following command:\n$ git merge origin/hotfix If you aren’t the author of the hotfix branch and you instead want your own hotfix branch, you can base it off the remote-tracking branch using the following command:\n$ git branch -b hotfix origin/hotfix Branch hotfix set up to track remote branch hotfix from origin. Switched to a new branch 'hotfix'","rebasing#Rebasing":"Within Git there are two ways to integrate changes from one branch into another: using merge or rebase. In the example below the history has diverged; there are commits on both the branches you would like to integrate.\nThe most simple way to integrate the work of the hotfix would be to use the git merge command. This will result in a three-way merge between the two latests snapshots (C4 and C5) and there common ancestor (C3) creating a merge-commit (C6).\nInstead of merge you could’ve used rebase to integrate the changes in the hotfix in the master branch. When rebasing, Git will take all the changes that were committed on one branch and replay them on a different branch. We could for example rebase the hotfix branch onto the master branch:\n$ git checkout hotfix $ git rebase master First, rewinding head to replay your work on top of it... Applying: Fix README.md file. When performing the rebase, Git wil do the following actions:\nGo back to the common ancestor of the two branches (C3). Store the changes in temporary files of all the commits after the common ancestor on your current branch (hotfix). Reset the current branch to the branch you’re rebasing onto (master). Applying each change (re-apply C4, now known as C4'). Because the commit C4' pointed to by the branch hotfix was directly ahead of the commit C5, the commit pointed to by themaster branch, Git is able to perform a “fast-forward” merge:\n$ git checkout master Switched to branch 'master' $ git merge hotfix Updating 8fb061c..527a84d Fast-forward README.md | 2 +- 1 file changed, 1 insertion(+), 1 deletion(-) This result in both the hotfix and master branch pointing to the C4' commit:\nBoth C4' (using rebase) and C6 (using merge) resulted in the same file contents, but the Git history is different. The rebase made the history a bit cleaner, resulting in a linear history. Even though the history shows that the work happened in series, it actually happened in parallel.\nUnfortunately rebasing has its drawbacks; you don not want to rebase commits that exists outside your repository and the other people my have based work on!\nDuring a rebase you will be abandoning commits and create new ones that have the similar content but are actually different (e.g. pointer to another parent). If you (forcefully) push you work, you force other collaborators to rebase their work. Things won’t become cleaner this way…\nSuppose you’ve started working on the master branch locally while in the meanwhile another collaborator forcefully pushed his rebased master branch, resulting in some part of the history being rewritten on the remote origin/master branch. When you execute a git pull, Git will merge the rebased origin/master branch into your local master branch.\nThe history between the origin/master and master branch have been diverged, forcing you to rebase you local master branch onto origin/master, which might further confuse other colleborators.\nIf for some reason someone has rebased a branch you based your work on you can simplify things by running git pull --rebase instead of git pull. Or you could do is manually using the following commands:\n$ git fetch $ git rebase /","remote-branches#Remote Branches":"As the title suggests, remote branches are pointers in your remote repository. You can get a full list of all remote references (including branches, tags, and so) using the git ls-remote or git remote show commands. Remote-tracking branches can’t be changed locally, they are updated by Git whenever you do any network communication.\nWhen cloning a repository using the git clone command the default remote is called origin. The names of the remote-tracking branches take the form of /. Cloning the blog will result in the local master branch originated from the remote origin/master branch:\n$ git clone https://github.com/roaldnefs/roaldnefs.com.git $ cd roaldnefs.com $ git status On branch master Your branch is up to date with 'origin/master'. If the master branch contains a few commits, this results in the following situation:\nThe origin remote isn’t different from other remotes it’s, just the default alias for the remote after running git clone. You can show all the remotes using the git remote -v command:\n$ git remote -v origin\thttps://github.com/roaldnefs/roaldnefs.com.git (fetch) origin\thttps://github.com/roaldnefs/roaldnefs.com.git (push)","summary#Summary":"There are multiple ways to integrate changes in two (or more) branches using merge, rebase or cherry-pick. They all have there advantages and disadvantages. In most cases merge is perferred over rebase and cherry-pick for the simple reason that most people tend to understand the merge workflow fairly easily, and the rebase and cherry-pick workflow is considered more advantage.","switching-branches#Switching Branches":"After creating a new branch you probably want to switch to that branch. This can be done using the git checkout command. The command below will switch to the develop branch.\n$ git checkout develop This results in HEAD pointing to the develop branch:\nAfter creating a new commit the master branch is still pointing to the same commit, while the develop branch has moved forward.\nUsing the following command we can switch back to the master branch. This will move the HEAD pointer back to master.\n$ git checkout master Creating a new commit at this point will result in diverged history. Both commits are isolated in separate branches, and can be merged together when you’re ready.\nThis can also be shown using the git log --oneline --decorate --graph --all command. By default the git log command will not show all of the branch, this the --all options is required.\n$ git log --oneline --decorate --graph --all * 8fb061c (HEAD -\u003e master) Add authors to README.md | * 37d648d (develop) Add LICENSE file |/ * 3c71f2e Update README.md * 13d0d67 Initial commit It’s also possible to create a new branch and switch to it at the same time with the following command:\n$ git checkout -b"},"title":"Git Branching"},"/posts/2020/12/how-to-automatically-generate-clients-for-your-rest-api/":{"data":{"":"While helping a colleague with adding some code to the bunq Python SDK to allow him to retrieve some additional information from the API (bunq/sdk_python#148), we noticed that the SDK was automatically generated. We’ve eventually ended up monkey patching the SDK, as we couldn’t make a pull request to the SDK and the API specification or SDK generator wasn’t publicly available. However, this aroused some interest about the automatic generation of API clients.\nIn this post we will automatically generate a REST API client based upon an OpenAPI specification. The OpenAPI specification allows REST APIs to be described in a standard programming language-agnostic way, making it possible for both humans and computers to interpret the specification.","automatically-generate-a-python-sdk#Automatically generate a Python SDK":"The OpenAPI Generator allows the generation of API client libraries and documentation for multiple languages and frameworks given an OpenAPI specification. This includes generators for Python, Go, Java and many more.\nEven though the OpenAPI Generator is written in Java, you can use the pre-built Docker image to act as a standalone executable. The command below will generate a Python SDK based upon the specification (openapi.yaml):\n$ docker run --rm \\ -v ${PWD}:/local openapitools/openapi-generator-cli generate \\ -i /local/openapi.yaml \\ -g python \\ -o /local/out/python \\ --additional-properties=packageName=xkcd_client,projectName=xkcd_client After execution the newly generated Python SDK is available in ./out/python and comes included with the necessary documentation to start using it. It even comes with a .openapi-generator-ignore file which let you specify files to prevent them from being overwritten by the generator.","conclusion#Conclusion":"In general, it’s quite possible to automatically generate a REST API based upon OpenAPI specification. Even for REST APIs that do not include a OpenAPI specification by default you can easily describe the API in a specification file to allow the API client generation. Although this post didn’t go in depth about API authentication, cookie usage or other HTTP methods, they are all possible features of the OpenAPI specification and OpenAPI Generator. However, results and options may differ based upon the language or framework you would like to generate the SDK in.\nEven though the generated code may seem a bit rough, it’s well documented and could be made more human friendly by improving the API specification.","improve-the-openapi-specification#Improve the OpenAPI specification":"Even though we can now use the newly generated SDK, it comes with some very generic class names and ill-favoured function names, e.g.:\nimport xkcd_client # Initialize a xkcd API client configuration = xkcd_client.Configuration(host=\"https://xkcd.com\") client = xkcd_client.ApiClient(configuration) api_instance = xkcd_client.api.default_api.DefaultApi(api_client) # Retrieve a comic by identifier api_response = api_instance.id_info0_json_get(614) Let’s improve the OpenAPI specification to allow the generation of some more human friendly code. To rename the DefaultApi class we will need to logical group endpoints by adding the tags option:\n... paths: # Retrieve the current comic /{id}/info.0.json: get: # A list of tags to logical group operations by resources and any other # qualifier. tags: - comic description: Returns comic based on ID ... In order to rename the function DefaultApi.id_info0_json_get we can specify a unique operationId to allow tools and libraries to uniquely identify an operation:\n... paths: # Retrieve the current comic /{id}/info.0.json: get: # A list of tags to logical group operations by resources and any other # qualifier. tags: - comic description: Returns comic based on ID # Unique identifier for the operation, tools and libraries may use the # operationId to uniquely identify an operation. operationId: getComic ... The full OpenAPI specification of the xkcd JSON interface is available on GitHub.","using-the-generated-python-sdk#Using the generated Python SDK":"After generation of the Python SDK we can create a Python virtual environment and install the generated xkcd Python API client using the following commands:\n$ python3 -m venv env $ source env/bin/activate $ pip install -e ./out/python After installing the generated API client, we could for example retrieve the xkcd comic about an API using the following Python snippet:\nfrom pprint import pprint from xkcd_client import Configuration, ApiClient, ApiException from xkcd_client.api.comic_api import ComicApi configuration = Configuration(host=\"https://xkcd.com\") # Enter a context with an instance of the API client with ApiClient(configuration) as client: # Create an instance of the API class instance = ComicApi(client) try: # Retrieve the API comic api_response = instance.get_comic_by_id(1481) pprint(api_response) except ApiException as exc: print(\"Exception when calling ComicApi-\u003eget_comic_by_id: {0}\\n\".format(exc))","write-the-openapi-specification#Write the OpenAPI specification":"Even though quite a lot of REST APIs nowadays come included with an OpenAPI specification, this is not the case for all of them. In this post we will be using the JSON interface on xkcd as an example. We will start by describing the OpenAPI specification for the two existing endpoints:\nGET: http://xkcd.com/info.0.json (current comic) GET: http://xkcd.com/614/info.0.json (comic #614) Let’s start by creating a file called openapi.yaml. After filling in some basic information such as the API information and available server(s), we can add the individual endpoints. The specification below only contains the endpoint for retrieving a xkcd comic by its identifier.\nopenapi: 3.0.0 info: version: 1.0.0 title: xkcd description: 'A webcomic of romance, sarcasm, math, and language.' servers: - url: https://xkcd.com/ description: Official xkcd JSON interface paths: # Retrieve a comic by its identifier /{id}/info.0.json: get: tags: - comic description: Returns comic based on ID summary: Find comic by ID operationId: getComicById parameters: - name: id in: path required: true schema: type: integer responses: '200': description: Successfully returned a commmic content: application/json: schema: type: object properties: link: type: string img: type: string title: type: string"},"title":"How to Automatically Generate Clients for your REST API"},"/posts/2022/11/spoofing-microchips-used-for-animal-identification/":{"data":{"":"A microchip implanted under the skin of an animal can be used for identification purposes. The microchips are using Radio Frequency Identification (RFID) technology to transmit an unique tag number using an electromagnetic field when in close contact with an nearby RFID reader device. The microchips are often used to help return lost pets quickly. The unique chip numbers are registered in a designated portal to let animal shelters, animal control officers and veterinarians to look up contact information of the animal’s owner. During animal trials and events the microchips are often used to verify the animals identity.\nThis post will demonstrate how an attacker can create an “authentic” microchip by writing properly formatted data on blank or rewritable transponder, also known as spoofing. Unfortunately, the RFID reader devices do not differentiate between the authentic and spoofed microchips. The main intention behind this post is to encourage more secure ways of identifying animals instead of solely trusting the implanted microchip.","buying-rewritable-fdx-b-microchips-and-programmers#Buying (re)writable FDX-B microchips and programmers":"Although some countries regulate who can buy, implant and register microchips it’s still possible to buy micropships as an individual. In the Netherlands for example, only registered microchippers and veterinarians are allowed to microchip dogs and register the microchip numbers at a designated portal1. However it’s still possible for non-registered microchippers to find and buy (re)writable ICAR certificated FDX-B microchips online as shown by the advert in the figure below.\nThe rewritable microchips often come with a preprogrammed tag number that still needs to be overwritten in order to spoof an authentic number, this can be done using a so called programmer. The RFID programmers often come included with the required software to write properly formatted data to the transponders. The figures below show two programmers which can be used to write valid FDX-B microchips. The Proxmark 3 device even allows the user to simulate a microchip.\nAs shown by the example adverts in the figures above the total cost of spoofing a microchip including the required programmer and shipping is just around €50. The attacker will only need a single programmer to spoof additional microchips, lowering the cost per spoofed microchip even more.","conclusion#Conclusion":"Although microchips might help return lost pets more quickly, they should not be solely trusted to verify the animals identity. An attacker can create an “authentic” microchip by writing properly formatted data on blank or rewritable transponder, also known as spoofing. Unfortunately, the RFID reader devices do not differentiate between the authentic and spoofed microchips.\nhttps://business.gov.nl/regulation/registering-dogs-and-pet-passports/ ↩︎","introduction-to-fdx-b#Introduction to FDX-B":"FDX-B is a protocol used as a common format for transponders. The protocol is fully described in ISO 11784 and ISO 11785. The transponders operate in the 134.2kHz band and use a biphase encoding scheme to transmit the data.\nThe power used for transmitting data is drawn from the electromagnetic field transmitted by the RFID reader when in close contact with the transponder. The transponders can carry up to 128 bits of data. The table below shows the example of the decoded FDX-B data in bits for the tag number 528140000795552.\nThe data is structured according to the FDX-B protocol and will be transmitted with the least significant bit first (lsb). The 11 bit header is used to indicate the beginning of the data block. A logic 1 bit is sent after every 8 bits to differentiate the data from the header. The header is followed by the 38 bit national code, which corresponds to a 12 digit decimal code to uniquely identify an animal. This is followed by the 10 bit, 3 decimal digits, country code (e.g. 528 for the Netherlands). The next application identicator bit indicates whether the 24 extra application data bits are used at the end of the block. The 14 bits followed after the application identicator bit are reserved for future use. The next bit is the animal application identicator. When the transponder is used for animal identification purposes this bit is set to 1. To be able to verify the data block, a 16 bit checksum is calculated according to the ISO 11784 \u0026 11785 standards.","spoofing-a-fdx-b-microchip#Spoofing a FDX-B microchip":"The examples below will show how a custom chip number can be written to a (re)writable transponder and allow it to be scanned as an authentic microchip using a RFID reader. This example uses a Proxmark 3 programmer to write the properly formatted data on the transponder. For example, the command for writing tag number 528140000795552 to the transponder:\npm3 \u003e lf fdxb clone --em --country 528 --national 140000795552 --animal After writing the data to the rewritable transponder it can also be read by the Proxmark 3 to verify whether the write command was successful. The example command below shows the formatted data after writing the tag number to the transponder:\npm3 \u003e lf fdxb reader [+] FDX-B / ISO 11784/5 Animal [+] Animal ID 528-140000795552 [+] National Code 140000795552 (0x2098B29BA0) [+] Country Code 528 - Kingdom of the Netherlands [+] Reserved/RFU 0 (0x0000) [+] Animal bit set? True [+] Data block? False [value 0x0] [+] RUDI bit? False [+] User Info? 0 (RFU) [+] Replacement No? 0 (RFU) [+] CRC-16 0xF283 (ok) [+] Raw 05 D9 4D 19 04 21 00 01 When scanning the spoofed microchip using a common RFID reader device it shows as an authentic microchip. By writing the extended/application data using the --extended flag some readers will even be showing the spoofed microchip temperature.\nThe above figure shows the spoofed microchip with tag number 528140000795552 being scanned by a RFID reader device. The reader acts as if it is an authentic microchip, to make the user believe that this must actually be the dog with this particular chip number."},"title":"Spoofing Microchips used for Animal Identification"},"/posts/2024/01/committing-changes-to-a-pull-request-branch-created-from-a-fork/":{"data":{"":"Sometimes a pull request on GitHub.com needs some work before it can be merged into the project but you don’t want to force the required work on the pull requests original author. You’re allowed to make changes to the pull request if they are opened to a repository you have push access to, the fork is user-owned, the user has granted the required permissions and there aren’t any branch restrictions that will prevent committing.\nAdd an additional remote for the forked project, e.g. git remote add roaldnefs git@github.com:roaldnefs/salt-lint.git.\nFetch all branches using the git fetch roaldnefs command.\nSwitch to the branch in the forked project, e.g. git checkout my-branch.\nYou can now do anything with the branch. You can rebase it, run in locally or add new commits.\nAfter you’ve made the necessary changes you simply push the changes using the git push command.\nYour changes should now be reflected in the original pull request on GitHub.com."},"title":"Committing Changes to a Pull Request Branch Created from a Fork"},"/posts/2024/12/how-to-extract-an-appimage-and-add-it-to-the-ubuntu-sidebar/":{"data":{"":"In this post, we’ll guide you through extracting an AppImage and integrating it into the Ubuntu sidebar for easy access. As an example, we’ll use SavvyCAN, a CANBus reverse engineering tool.","create-a-desktop-entry#Create a Desktop Entry":"Many extracted AppImages include a *.desktop file, but you’ll need to verify and customize it. For SavvyCAN, here’s an example of a complete desktop entry file:\n[Desktop Entry] Type=Application Name=SavvyCAN GenericName=CANBus reverse engineering tool Comment=Facilitates reverse engineering of canbus captures Exec=/opt/savvycan/AppRun %F Icon=/opt/savvycan/SavvyCAN.png Terminal=false Categories=Development;Electronics;IDE; MimeType=text/x-application; Keywords=embedded electronics;electronics;canbus;reverse engineering; X-Desktop-File-Install-Version=0.27 Save this content as savvycan.desktop.","download-the-appimage#Download the AppImage":"Start by downloading the AppImage file for the application you want to install. For this guide, we’ll use the SavvyCAN-x86_64.AppImage. Once the download is complete, you’ll need to make the AppImage executable to run it. Use the following command:\nchmod +x SavvyCAN-x86_64.AppImage","extract-the-appimage#Extract the AppImage":"For faster startup times and easier integration into the desktop environment, you can extract the AppImage. This also allows you to set it up as a regular desktop application with a sidebar shortcut.\nTo extract the AppImage, run the following command:\n$ ./SavvyCAN-x86_64.AppImage --appimage-extract This creates a directory named squashfs-root, which contains all the extracted files, including the AppRun file and (hopefully) the application’s icon.","install-the-desktop-entry#Install the Desktop Entry":"Install the desktop entry file using the desktop-file-install command. This validates and moves the file to /usr/share/applications:\nsudo desktop-file-install savvycan.desktop After completing these steps, SavvyCAN should appear in your application list. You can also pin it to the Ubuntu sidebar for quick access.","move-the-extracted-files-to-a-permanent-location#Move the extracted files to a permanent location":"Move the squashfs-root directory to a permanent location, such as /opt, and rename it for easier access:\nsudo mv squashfs-root /opt/savvycan","resolve-missing-dependencies-if-needed#Resolve missing dependencies (if needed)":"When you attempt to run the AppImage, you might encounter an error if a required library, such as libfuse.so.2, is missing. For example:\n$ ./SavvyCAN-x86_64.AppImage dlopen(): error loading libfuse.so.2 AppImages require FUSE to run. You might still be able to extract the contents of this AppImage if you run it with the --appimage-extract option. To resolve this, install the missing libfuse library using the following command (tested on Ubuntu 24.04):\nsudo apt install libfuse2t64 After installing the library, you should be able to execute the AppImage by double-clicking it or running it from the terminal."},"title":"How to extract an AppImage and add it to the Ubuntu Sidebar"},"/tools/":{"data":{"":"I often get questions about the specific software or hardware I use. Since my setup changes frequently, this page serves as a living document where I keep everything up to date. It’s a handy resource to share when people ask. If you notice something missing or have a suggestion, feel free to reach out, and I’ll make sure to add it.","automotive#Automotive":"","hardware#Hardware":"CANable Pro: A small low-cost open source USB to CAN adapter. CL2000: A CAN bus logger and USB interface with a real-time clock.","hardware-1#Hardware":"YARD Stick One: A versatile sub-1 GHz wireless testing tool controlled via your computer. I own multiple units and pair them with the ANT500, a telescopic antenna designed to operate across 75 MHz to 1 GHz. See the related post about updating the YARD Stick One firmware. HackRF One: A Software Defined Radio peripheral capable of transmission or reception of radio signals from 1 MHz to 6 GHz.","hardware-2#Hardware":"Proxmark 3 Easy: An RFID swiss-army tool, allowing for both high and low level interactions with the vast majority of RFID tags and systems. I own a clone of the official Proxmark. See the related post about spoofing microschips. ACR122U: An USB NFC Reader. Halo scanner: A handheld scanner used to scan the microchip numbers of animals. See the related post about spoofing microschips.","hardware-3#Hardware":"GreatFET One: A powerful USB interface for hardware hacking and development.","hardware-4#Hardware":"KSGER T12: A soldering station with configurable temperature and interchangeable tips.","hardware-5#Hardware":"SouthOrd PXS-14: A 14-piece lock pick set.","hardware-hacking#Hardware Hacking":"Hardware hacking is all about exploring, testing, and interacting with physical devices in creative and unconventional ways. Whether it’s working with wireless communication protocols or interfacing with USB devices, having the right tools is essential. Below, I’ve listed some of the hardware I rely on for RF and USB hacking, along with a brief overview of how I use them in my projects.","lockpicking#Lockpicking":"","rf#RF":"","rfidnfc#RFID/NFC":"","software#Software":"SavvyCAN: A cross platform CAN bus reverse engineering and capture tool.","soldering#Soldering":"","usb#USB":""},"title":"Tools"},"/training/":{"data":{"":"Whether you’re a seasoned engineer, a curious developer, or a security-minded hobbyist ready to explore new territory, my workshops are designed to empower hands-on learning.","-hands-on-hacking-automotive-systems#🚗 Hands-on Hacking Automotive Systems":"Today’s vehicles are computers on wheels, and just like any other connected system, they require strong security. This foundational workshop teaches participants how vehicles communicate, and where vulnerabilities may exist.","book-a-session#Book a Session":"Interested in hosting a workshop for your company, school, or event? Contact me at info@roaldnefs.com.","format-options#Format Options":"Choose the learning experience that best fits your audience, time, and depth of exploration.\nDuration Style Description 1-Hour Talk Lecture High-level introduction and live demonstrations Half-Day Workshop Hands-on Lab Guided CAN bus sniffing + ECU communication exercises Full-Day Technical Training Deep Dive Reverse engineering demos, tool setup, practice lab kits","what-youll-learn#What You\u0026rsquo;ll Learn":"How modern vehicle networks work. Guided, hands-on interaction with CAN bus tooling in a controlled lab environment, including: Reading and interpreting CAN traffic. Sending CAN traffic. Executing attacks on the CAN bus.","who-this-is-for#Who This Is For":"IT Engineers Cybersecurity Researchers Students \u0026 Professionals entering cybersecurity"},"title":"Training \u0026 Workshops"}}